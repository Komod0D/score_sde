{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 09:58:07.803339: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from losses import TrainState\n",
    "from flax.training import checkpoints\n",
    "from flax import jax_utils as flax_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from models import super_simple\n",
    "from models import utils as mutils\n",
    "import sampling\n",
    "import losses\n",
    "\n",
    "from configs.vp.disk_inner_ssim_continuous import get_config\n",
    "from configs.vp.disk_ssim_cls_continuous import get_config as get_config_cls\n",
    "import sde_lib\n",
    "import datasets\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "model_rng, sampling_rng = jax.random.split(rng)\n",
    "config = get_config()\n",
    "score_model, init_model_state, init_model_params = mutils.init_model(model_rng, config)\n",
    "optimizer = losses.get_optimizer(config)\n",
    "\n",
    "state = TrainState.create(tx=optimizer, apply_fn=score_model.apply,\n",
    "                          params=init_model_params, mutable_state=init_model_state,\n",
    "                          rng=rng)\n",
    "workdir = '/home/komodo/Documents/uni/thesis/backups/disk_inner_modern/ssim/'\n",
    "ckpt_model_state = checkpoints.restore_checkpoint(os.path.join(workdir, 'checkpoints'), state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup SDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.training.sde.lower() == 'vpsde':\n",
    "    sde = sde_lib.VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "    sampling_eps = 1e-3\n",
    "elif config.training.sde.lower() == 'subvpsde':\n",
    "    sde = sde_lib.subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "    sampling_eps = 1e-3\n",
    "elif config.training.sde.lower() == 'vesde':\n",
    "    sde = sde_lib.VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
    "    sampling_eps = 1e-5\n",
    "else:\n",
    "    raise NotImplementedError(f\"SDE {config.training.sde} unknown.\")\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "\n",
    "sampling_shape = (config.training.batch_size // jax.local_device_count(), config.data.image_size,\n",
    "                config.data.image_size, config.data.num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Points\n",
    "Samples 16 * batch_size points for every time step (50 time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/komodo/miniconda3/envs/testing/lib/python3.11/site-packages/jax/_src/xla_bridge.py:1174: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ScopeParamShapeError",
     "evalue": "Initializer expected to generate shape (32, 32) but got shape (32, 2) instead for parameter \"kernel\" in \"/Dense_3\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopeParamShapeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m next_rng\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     17\u001b[0m ns \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mfloor(jnp\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, sde\u001b[38;5;241m.\u001b[39mN, num_sample_steps))\u001b[38;5;241m.\u001b[39mastype(jnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m---> 19\u001b[0m a, b \u001b[38;5;241m=\u001b[39m both_vmap(next_rng, ns)\n\u001b[1;32m     20\u001b[0m a_sq \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mreshape((num_rng, num_sample_steps, config\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mbatch_size, a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     21\u001b[0m temp \u001b[38;5;241m=\u001b[39m a_sq\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape((num_sample_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(r, t)\u001b[0m\n\u001b[1;32m      7\u001b[0m num_train_steps \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mn_iters\n\u001b[1;32m      9\u001b[0m rng_vmap \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m r, t: sampling_fn(r, pstate, jnp\u001b[38;5;241m.\u001b[39marray([t])), in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m both_vmap \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m r, t: rng_vmap(r, t), in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m), out_axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfold_in(rng, jax\u001b[38;5;241m.\u001b[39mhost_id())\n\u001b[1;32m     13\u001b[0m rng, \u001b[38;5;241m*\u001b[39mnext_rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng, num\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mlocal_device_count() \u001b[38;5;241m*\u001b[39m num_rng \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(r, t)\u001b[0m\n\u001b[1;32m      6\u001b[0m pstate \u001b[38;5;241m=\u001b[39m flax_utils\u001b[38;5;241m.\u001b[39mreplicate(ckpt_model_state)\n\u001b[1;32m      7\u001b[0m num_train_steps \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mn_iters\n\u001b[0;32m----> 9\u001b[0m rng_vmap \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m r, t: sampling_fn(r, pstate, jnp\u001b[38;5;241m.\u001b[39marray([t])), in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m both_vmap \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m r, t: rng_vmap(r, t), in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m), out_axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mfold_in(rng, jax\u001b[38;5;241m.\u001b[39mhost_id())\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/sampling.py:437\u001b[0m, in \u001b[0;36mget_pc_sampler.<locals>.pc_sampler\u001b[0;34m(rng, state, N)\u001b[0m\n\u001b[1;32m    434\u001b[0m   x, x_mean \u001b[38;5;241m=\u001b[39m predictor_update_fn(step_rng, state, x, vec_t)\n\u001b[1;32m    435\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m rng, x, x_mean\n\u001b[0;32m--> 437\u001b[0m _, x, x_mean \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mfori_loop(\u001b[38;5;241m0\u001b[39m, N, loop_body, (rng, x, x))\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Denoising is equivalent to running one predictor step without adding noise.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inverse_scaler(x_mean \u001b[38;5;28;01mif\u001b[39;00m denoise \u001b[38;5;28;01melse\u001b[39;00m x), N \u001b[38;5;241m*\u001b[39m (n_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/sampling.py:434\u001b[0m, in \u001b[0;36mget_pc_sampler.<locals>.pc_sampler.<locals>.loop_body\u001b[0;34m(i, val)\u001b[0m\n\u001b[1;32m    432\u001b[0m x, x_mean \u001b[38;5;241m=\u001b[39m corrector_update_fn(step_rng, state, x, vec_t)\n\u001b[1;32m    433\u001b[0m rng, step_rng \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[0;32m--> 434\u001b[0m x, x_mean \u001b[38;5;241m=\u001b[39m predictor_update_fn(step_rng, state, x, vec_t)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rng, x, x_mean\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/sampling.py:361\u001b[0m, in \u001b[0;36mshared_predictor_update_fn\u001b[0;34m(rng, state, x, t, sde, model, predictor, probability_flow, continuous)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m   predictor_obj \u001b[38;5;241m=\u001b[39m predictor(sde, score_fn, probability_flow)\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictor_obj\u001b[38;5;241m.\u001b[39mupdate_fn(rng, x, t)\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/sampling.py:204\u001b[0m, in \u001b[0;36mReverseDiffusionPredictor.update_fn\u001b[0;34m(self, rng, x, t)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng, x, t):\n\u001b[0;32m--> 204\u001b[0m   f, G \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrsde\u001b[38;5;241m.\u001b[39mdiscretize(x, t)\n\u001b[1;32m    205\u001b[0m   z \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mnormal(rng, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    206\u001b[0m   x_mean \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m f\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/sde_lib.py:107\u001b[0m, in \u001b[0;36mSDE.reverse.<locals>.RSDE.discretize\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create discretized iteration rules for the reverse diffusion sampler.\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m f, G \u001b[38;5;241m=\u001b[39m discretize_fn(x, t)\n\u001b[0;32m--> 107\u001b[0m rev_f \u001b[38;5;241m=\u001b[39m f \u001b[38;5;241m-\u001b[39m batch_mul(G \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, score_fn(x, t) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability_flow \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.\u001b[39m))\n\u001b[1;32m    108\u001b[0m rev_G \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros_like(G) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability_flow \u001b[38;5;28;01melse\u001b[39;00m G\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rev_f, rev_G\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/models/utils.py:193\u001b[0m, in \u001b[0;36mget_score_fn.<locals>.score_fn\u001b[0;34m(x, t, rng)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m continuous \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sde, sde_lib\u001b[38;5;241m.\u001b[39msubVPSDE):\n\u001b[1;32m    189\u001b[0m   \u001b[38;5;66;03m# For VP-trained models, t=0 corresponds to the lowest noise level\u001b[39;00m\n\u001b[1;32m    190\u001b[0m   \u001b[38;5;66;03m# The maximum value of time embedding is assumed to 999 for\u001b[39;00m\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;66;03m# continuously-trained models.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m   labels \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m999\u001b[39m\n\u001b[0;32m--> 193\u001b[0m   model, state \u001b[38;5;241m=\u001b[39m model_fn(x, labels, rng)\n\u001b[1;32m    194\u001b[0m   std \u001b[38;5;241m=\u001b[39m sde\u001b[38;5;241m.\u001b[39mmarginal_prob(jnp\u001b[38;5;241m.\u001b[39mzeros_like(x), t)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# For VP-trained models, t=0 corresponds to the lowest noise level\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/models/utils.py:156\u001b[0m, in \u001b[0;36mget_model_fn.<locals>.model_fn\u001b[0;34m(x, labels, rng)\u001b[0m\n\u001b[1;32m    154\u001b[0m variables \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstates}\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train:\n\u001b[0;32m--> 156\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mapply(variables, x, labels, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mutable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), states\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m   rngs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m: rng}\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/uni/thesis/score_sde/models/super_simple.py:35\u001b[0m, in \u001b[0;36mSSimple.__call__\u001b[0;34m(self, x, t, train)\u001b[0m\n\u001b[1;32m     33\u001b[0m h2 \u001b[38;5;241m=\u001b[39m act(nn\u001b[38;5;241m.\u001b[39mDense(nf)(h1))\n\u001b[1;32m     34\u001b[0m h3 \u001b[38;5;241m=\u001b[39m act(nn\u001b[38;5;241m.\u001b[39mDense(nf)(h2))\n\u001b[0;32m---> 35\u001b[0m out \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDense(out_shape)(h3)[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m     37\u001b[0m out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m/\u001b[39m used_sigmas\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing/lib/python3.11/site-packages/flax/linen/linear.py:251\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;129m@compact\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    The transformed input.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m   kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_init,\n\u001b[1;32m    254\u001b[0m     (jnp\u001b[38;5;241m.\u001b[39mshape(inputs)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures),\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype,\n\u001b[1;32m    256\u001b[0m   )\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    258\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[1;32m    259\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_init, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype\n\u001b[1;32m    260\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing/lib/python3.11/site-packages/flax/core/scope.py:989\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m val, abs_val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(value_flat, abs_value_flat):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# NOTE: We could check dtype consistency here as well but it's\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# usefuleness is less obvious. We might intentionally change the dtype\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# for inference to a half float type for example.\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mshape(val) \u001b[38;5;241m!=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mshape(abs_val):\n\u001b[0;32m--> 989\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mScopeParamShapeError(\n\u001b[1;32m    990\u001b[0m         name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_text, jnp\u001b[38;5;241m.\u001b[39mshape(abs_val), jnp\u001b[38;5;241m.\u001b[39mshape(val)\n\u001b[1;32m    991\u001b[0m       )\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mutable_collection(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mScopeParamShapeError\u001b[0m: Initializer expected to generate shape (32, 32) but got shape (32, 2) instead for parameter \"kernel\" in \"/Dense_3\". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)"
     ]
    }
   ],
   "source": [
    "num_rng = 16\n",
    "num_sample_steps = 50\n",
    "\n",
    "# sampling_fn = pc_sampler\n",
    "sampling_fn = sampling.get_sampling_fn(config, sde, score_model, sampling_shape, inverse_scaler, sampling_eps)\n",
    "pstate = flax_utils.replicate(ckpt_model_state)\n",
    "num_train_steps = config.training.n_iters\n",
    "\n",
    "rng_vmap = jax.vmap(lambda r, t: sampling_fn(r, pstate, jnp.array([t])), in_axes=(0, None), out_axes=0)\n",
    "both_vmap = jax.vmap(lambda r, t: rng_vmap(r, t), in_axes=(None, 0), out_axes=1)\n",
    "\n",
    "rng = jax.random.fold_in(rng, jax.host_id())\n",
    "rng, *next_rng = jax.random.split(rng, num=jax.local_device_count() * num_rng + 1)\n",
    "next_rng = jnp.asarray(next_rng)[:, None, :]\n",
    "next_rng.shape\n",
    "\n",
    "ns = jnp.floor(jnp.linspace(0, sde.N, num_sample_steps)).astype(jnp.int32)\n",
    "\n",
    "a, b = both_vmap(next_rng, ns)\n",
    "a_sq = a.reshape((num_rng, num_sample_steps, config.training.batch_size, a.shape[-1]))\n",
    "temp = a_sq.transpose((1, 0, 2, 3)).reshape((num_sample_steps, -1, a.shape[-1]))\n",
    "xs = temp[:, :, 0]\n",
    "ys = temp[:, :, temp.shape[-1] - 1]\n",
    "jnp.mean(jnp.sum(temp**2, axis=-1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_ds, _ = datasets.get_dataset(config)\n",
    "gt = tf.stack([x['image'] for x in test_ds.take(num_rng)]).numpy().reshape(temp.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "limits = jnp.max(jnp.abs(temp[-1])) * 1.2\n",
    "left, right = -limits, limits\n",
    "\n",
    "circle = plt.Circle((0, 0), 1, color='r', fill=False)\n",
    "\n",
    "ax.add_patch(circle)\n",
    "line, = ax.plot(gt[:, 0], gt[:, gt.shape[-1] - 1], 'r+')\n",
    "\n",
    "ax.set_ylim(left, right)\n",
    "ax.set_xlim(left, right)\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4096, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 64\n",
    "ticks = jnp.linspace(left, right, N)\n",
    "coords = jnp.stack(jnp.meshgrid(ticks, ticks), axis=-1).reshape(-1, gt.shape[-1])\n",
    "\n",
    "ckpt = ckpt_model_state\n",
    "time_vmap = jax.vmap(lambda t: ckpt.apply_fn({'params': ckpt.params}, coords, jnp.tile(t, N**2),\n",
    "                                             train=False, mutable=False) * t**0.75)\n",
    "\n",
    "timesteps = jnp.linspace(sde.T, sampling_eps, sde.N)\n",
    "timesteps = jnp.stack([timesteps[ind] for ind in ns], axis=0)\n",
    "\n",
    "scores = -1. * time_vmap(timesteps).squeeze()\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data and Scores\n",
    "\n",
    "Note that score magnitudes are not completely to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "ax.set_xlim(left, right)\n",
    "ax.set_ylim(left, right)\n",
    "\n",
    "circle = plt.Circle((0, 0), 1, color='r', fill=False)\n",
    "ax.add_patch(circle)\n",
    "\n",
    "quiver = ax.quiver(coords[:, 0], coords[:, 1], scores[-1, :, 0], scores[-1, :, 1])\n",
    "line, = ax.plot(xs[-1, :], ys[-1, :], 'rx', alpha=0.7)\n",
    "\n",
    "\n",
    "axamp = fig.add_axes([0.01, 0.2, 0.0225, 0.63])\n",
    "t_slider = Slider(\n",
    "    ax=axamp,\n",
    "    label=\"T\",\n",
    "    valmin=0,\n",
    "    valmax=sde.N,\n",
    "    valinit=sde.N,\n",
    "    orientation=\"vertical\",\n",
    "    valstep=ns\n",
    ")\n",
    "\n",
    "# The function to be called anytime a slider's value changes\n",
    "def update(val):\n",
    "    ind = jnp.where(ns == val)[0]\n",
    "    quiver.set_UVC(scores[ind, :, 0], scores[ind, :, 1])\n",
    "    line.set_xdata(xs[ind])\n",
    "    line.set_ydata(ys[ind])\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "# register the update function with each slider\n",
    "t_slider.on_changed(update)\n",
    "\n",
    "ax.grid(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
